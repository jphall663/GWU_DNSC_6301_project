{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jphall663/GWU_DNSC_6301_project/blob/main/notebook/lecture_3/Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWnt46AmT8PH"
      },
      "source": [
        "# License \n",
        "***\n",
        "Copyright (C) 2017 -- 2022 J. Patrick Hall, jphall@gwu.edu\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVn5YXd2V-kU"
      },
      "source": [
        "## Installs and Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOR1L6Y1qiys"
      },
      "source": [
        "1. Standard Python imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvTkpRwET8PS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # import pandas for easy data manipulation using data frames\n",
        "\n",
        "from matplotlib import pyplot as plt # plotting\n",
        "import numpy as np                   # basic array and matric handling\n",
        "import seaborn as sns                # slightly better plotting \n",
        "\n",
        "# for model eval\n",
        "from sklearn.metrics import accuracy_score, f1_score, log_loss, mean_squared_error, roc_auc_score\n",
        "\n",
        "# to upload local files\n",
        "import io\n",
        "from google.colab import files  \n",
        "\n",
        "ROUND = 3              # generally, insane precision is not needed \n",
        "SEED = 12345           # seed for better reproducibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mm2GdpYBqm18"
      },
      "source": [
        "2. Install Java"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-YbUyqtUMNL"
      },
      "outputs": [],
      "source": [
        "# install Java for h2o backend\n",
        "!apt-get install default-jre\n",
        "!java -version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnoXiQyeqrLW"
      },
      "source": [
        "3. Install H2O"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Md93AynhUo6K"
      },
      "outputs": [],
      "source": [
        "# install h2o\n",
        "!pip install h2o "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bblRhKvqtlw"
      },
      "source": [
        "4. Import h2o package and required classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wECURngVVEEV"
      },
      "outputs": [],
      "source": [
        "# import h2o and required classes\n",
        "import h2o\n",
        "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
        "from h2o.grid.grid_search import H2OGridSearch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRjuduSaWD1K"
      },
      "source": [
        "## Load example data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFdzLsXSq1vw"
      },
      "source": [
        "5. Upload class example data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWUunZLpVTiR"
      },
      "outputs": [],
      "source": [
        "# special google collab command to upload a file from computer\n",
        "uploaded = files.upload() # REQUIRES STUDENT INPUT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3oh8A5gWIcu"
      },
      "outputs": [],
      "source": [
        "# 6\n",
        "uploaded.keys() # what is stored in that Python object?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8JqTohvq70h"
      },
      "source": [
        "7. Covert to Pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MxbxgL2WYza"
      },
      "outputs": [],
      "source": [
        "# convert data to Pandas DataFrame\n",
        "raw = pd.read_csv(io.StringIO(uploaded['loan_clean.csv'].decode('utf-8'))) # name in quotes here must match name in quotes directly above "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split training data into three partitions for improved model selection\""
      ],
      "metadata": {
        "id": "_VHhtn1cY3IL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Add partition marker to raw data and split into train, valid, and test data"
      ],
      "metadata": {
        "id": "AfHyYryaap9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ALWAYS set a random seed when working with randomness\n",
        "np.random.seed() # REQUIRES STUDENT INPUT\n",
        "raw['partition'] = np.random.choice(3, raw.shape[0])\n",
        "train = raw[raw['partition'] == 0].copy(deep=True)\n",
        "valid = raw[raw['partition'] == 1].copy(deep=True)\n",
        "test = raw[raw['partition'] == 2].copy(deep=True)\n",
        "\n",
        "print('Training data rows: %d,training data columns: %d' % (train.shape[0], train.shape[1]))\n",
        "print('Validation data rows: %d,training data columns: %d' % (valid.shape[0], valid.shape[1]))\n",
        "print('Test data rows: %d,training data columns: %d' % (test.shape[0], test.shape[1]))\n",
        "\n",
        "assert(raw.shape[0] == train.shape[0] + valid.shape[0] + test.shape[0]) # test that splits sum to original data size"
      ],
      "metadata": {
        "id": "gD60BqKOZCX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Add cross-validation market to test set"
      ],
      "metadata": {
        "id": "KdTOuakRdY4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid.loc[:, 'fold'] = np.random.choice(5, valid.shape[0])\n",
        "valid.head()"
      ],
      "metadata": {
        "id": "8MNcG7ogdUxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bkgid47Aea1f"
      },
      "source": [
        "## Train penalized GLM model to predict loan default with validation data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmhXrsVcT8PT"
      },
      "source": [
        "10. Assign global constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGaK5VDxT8PX"
      },
      "outputs": [],
      "source": [
        "x_names = [] # REQUIRES STUDENT INPUT\n",
        "y_name = ''# REQUIRES STUDENT INPUT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ds6cmuzrR8I"
      },
      "source": [
        "11. Start h2o server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "002yVhOjQJEj"
      },
      "outputs": [],
      "source": [
        "# start h2o\n",
        "h2o.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OECkjvsrU8O"
      },
      "source": [
        "12. Function for penalized GLM training that selects good alpha and lamda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vh1_CH3KT8Pw"
      },
      "outputs": [],
      "source": [
        "def glm_grid(x_names, y_name, htrain, hvalid=None, seed_=SEED):\n",
        "\n",
        "    \"\"\" Wrapper function for penalized GLM with alpha and lambda search.\n",
        "    :param x_names: List of inputs.\n",
        "    :param y_name: Name of target variable.\n",
        "    :param htrain: Training H2OFrame.\n",
        "    :param hvalid: Validation H2OFrame, default None.\n",
        "    :param seed_: Random seed for better reproducibility, default 12345.\n",
        "    :return: Best H2OGeneralizedLinearEstimator.\n",
        "    \"\"\"\n",
        "\n",
        "    alpha_opts = [0.01, 0.25, 0.5, 0.99]  # REQUIRES STUDENT INPUT\n",
        "\n",
        "    # define search criteria\n",
        "    # i.e., over alpha\n",
        "    # lamda search handled by lambda_search param below\n",
        "    hyper_parameters = {'alpha': alpha_opts}\n",
        "\n",
        "    # initialize grid search\n",
        "    grid = H2OGridSearch(\n",
        "        H2OGeneralizedLinearEstimator(family=\"binomial\",\n",
        "                                      lambda_search=True,\n",
        "                                      seed=seed_),\n",
        "        hyper_params=hyper_parameters)\n",
        "\n",
        "    # execute training w/ grid search\n",
        "    grid.train(y=y_name,\n",
        "               x=x_names,\n",
        "               training_frame=htrain,\n",
        "               validation_frame=hvalid,\n",
        "               seed=seed_)\n",
        "\n",
        "    # return entire grid of models\n",
        "    return grid\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJCIY9YMresM"
      },
      "source": [
        "13. Convert from Pandas DataFrames to H2OFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOJULlWHQ_sH"
      },
      "outputs": [],
      "source": [
        "# training data\n",
        "htrain = h2o.H2OFrame(train) # load Pandas DataFrame in H2OFrame\n",
        "htrain[y_name] = htrain[y_name].asfactor() # ensures h2o treats y/target as categorical and not numeric\n",
        "\n",
        "# validation data\n",
        "hvalid = h2o.H2OFrame(valid) \n",
        "hvalid[y_name] = hvalid[y_name].asfactor() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zVAEjAzrnWT"
      },
      "source": [
        "14. Train model using `glm_grid` function with validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTUV8GggrjyS"
      },
      "outputs": [],
      "source": [
        "loan_grid =  # REQUIRES STUDENT INPUT"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. View validation AUC for models in grid search"
      ],
      "metadata": {
        "id": "zdkObSYxh20D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cycle through grid search results and print valid AUC\n",
        "for i in range(0, 4):\n",
        "  candidate_glm = loan_grid.get_grid()[i]\n",
        "  print('Model %d validation AUC: %.4f' % (i, candidate_glm.auc(valid=True)))\n",
        "  print(loan_grid.get_grid()[i].summary())"
      ],
      "metadata": {
        "id": "1cfPFmk7hvDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. Score grid search models on validation set"
      ],
      "metadata": {
        "id": "7dY1Ds39jSC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores_frame = pd.DataFrame(valid[[y_name, 'fold']].copy(deep=True))\n",
        "scores_frame = scores_frame.reset_index(drop=True)\n",
        "for i in range(0, 4):\n",
        "  model_name = 'glm_' + str(i)\n",
        "  scores_frame[model_name] = loan_grid.get_grid()[i].predict(hvalid)['p1'].as_data_frame()"
      ],
      "metadata": {
        "id": "rndljlTbjRef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Utility function for max. accuracy"
      ],
      "metadata": {
        "id": "a4zjuXvrmRxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def max_acc(y, phat, res=0.01): \n",
        "\n",
        "    \"\"\" Utility function for finding max. accuracy at some cutoff. \n",
        "    \n",
        "        :param y: Known y values.\n",
        "        :param phat: Model scores.\n",
        "        :param res: Resolution over which to search for max. accuracy, default 0.01.\n",
        "        :return: Max. accuracy for model scores.\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    # init frame to store acc at different cutoffs\n",
        "    acc_frame = pd.DataFrame(columns=['cut', 'acc'])\n",
        "    \n",
        "    # copy known y and score values into a temporary frame\n",
        "    temp_df = pd.concat([y, phat], axis=1)\n",
        "    \n",
        "    # find accuracy at different cutoffs and store in acc_frame\n",
        "    for cut in np.arange(0, 1 + res, res):\n",
        "        temp_df['decision'] = np.where(temp_df.iloc[:, 1] > cut, 1, 0)\n",
        "        acc = accuracy_score(temp_df.iloc[:, 0], temp_df['decision'])\n",
        "        acc_frame = acc_frame.append({'cut': cut,\n",
        "                                      'acc': acc},\n",
        "                                     ignore_index=True)\n",
        "\n",
        "    # find max accurcay across all cutoffs\n",
        "    max_acc = acc_frame['acc'].max()\n",
        "    \n",
        "    # house keeping\n",
        "    del acc_frame, temp_df\n",
        "    \n",
        "    return max_acc"
      ],
      "metadata": {
        "id": "J0PbCE3BmR7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. Utility function for max. F1"
      ],
      "metadata": {
        "id": "8RJ9ON8FmThm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def max_f1(y, phat, res=0.01): \n",
        "    \n",
        "    \"\"\" Utility function for finding max. F1 at some cutoff. \n",
        "    \n",
        "        :param y: Known y values.\n",
        "        :param phat: Model scores.\n",
        "        :param res: Resolution over which to search for max. F1, default 0.01.\n",
        "        :return: Max. F1 for model scores.\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    # init frame to store f1 at different cutoffs\n",
        "    f1_frame = pd.DataFrame(columns=['cut', 'f1'])\n",
        "    \n",
        "    # copy known y and score values into a temporary frame\n",
        "    temp_df = pd.concat([y, phat], axis=1)\n",
        "    \n",
        "    # find f1 at different cutoffs and store in acc_frame\n",
        "    for cut in np.arange(0, 1 + res, res):\n",
        "        temp_df['decision'] = np.where(temp_df.iloc[:, 1] > cut, 1, 0)\n",
        "        f1 = f1_score(temp_df.iloc[:, 0], temp_df['decision'])\n",
        "        f1_frame = f1_frame.append({'cut': cut,\n",
        "                                    'f1': f1},\n",
        "                                    ignore_index=True)\n",
        "        \n",
        "    # find max f1 across all cutoffs\n",
        "    max_f1 = f1_frame['f1'].max()\n",
        "    \n",
        "     # house keeping\n",
        "    del f1_frame, temp_df\n",
        "    \n",
        "    return max_f1"
      ],
      "metadata": {
        "id": "hcy4OfutmUYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Apply Caruana et al. 2004 cross-validated ranking model selection "
      ],
      "metadata": {
        "id": "9lt0ZTtfiu3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_frame = pd.DataFrame() # init frame to hold score ranking\n",
        "metric_list = ['acc', 'auc', 'f1', 'logloss', 'mse'] # metric to use for evaluation\n",
        "\n",
        "# create eval frame row-by-row\n",
        "for fold in sorted(scores_frame['fold'].unique()): # loop through folds \n",
        "    for metric_name in metric_list: # loop through metrics\n",
        "        \n",
        "        # init row dict to hold each rows values\n",
        "        row_dict = {'fold': fold,\n",
        "                    'metric': metric_name}\n",
        "        \n",
        "        # cache known y values for fold\n",
        "        fold_y = scores_frame.loc[scores_frame['fold'] == fold, y_name]\n",
        "\n",
        "        for col_name in scores_frame.columns[2:]:\n",
        "\n",
        "            # cache fold scores\n",
        "            fold_scores = scores_frame.loc[scores_frame['fold'] == fold, col_name]\n",
        "\n",
        "            # calculate evaluation metric for fold\n",
        "            # with reasonable precision \n",
        "            \n",
        "            if metric_name == 'acc':\n",
        "                row_dict[col_name] = np.round(max_acc(fold_y, fold_scores), ROUND)\n",
        "                \n",
        "            if metric_name == 'auc':\n",
        "                row_dict[col_name] = np.round(roc_auc_score(fold_y, fold_scores), ROUND)\n",
        "                \n",
        "            if metric_name == 'f1':\n",
        "                row_dict[col_name] = np.round(max_f1(fold_y, fold_scores), ROUND) \n",
        "                \n",
        "            if metric_name == 'logloss':\n",
        "                row_dict[col_name] = np.round(log_loss(fold_y, fold_scores), ROUND)\n",
        "                \n",
        "            if metric_name == 'mse':\n",
        "                row_dict[col_name] = np.round(mean_squared_error(fold_y, fold_scores), ROUND)\n",
        "        \n",
        "        # append row values to eval_frame\n",
        "        eval_frame = eval_frame.append(row_dict, ignore_index=True)\n",
        "\n",
        "# init a temporary frame to hold rank information\n",
        "rank_names = [name + '_rank' for name in eval_frame.columns if name not in ['fold', 'metric']]\n",
        "rank_frame = pd.DataFrame(columns=rank_names)        \n",
        "\n",
        "# set columns to necessary order\n",
        "eval_frame = eval_frame[['fold', 'metric'] + [name for name in sorted(eval_frame.columns) if name not in ['fold', 'metric']]]\n",
        "\n",
        "# determine score ranks row-by-row\n",
        "for i in range(0, eval_frame.shape[0]):\n",
        "        \n",
        "        # get ranks for row based on metric\n",
        "        metric_name = eval_frame.loc[i, 'metric']\n",
        "        if metric_name in ['logloss', 'mse']:\n",
        "            ranks = eval_frame.iloc[i, 2:].rank().values\n",
        "        else:\n",
        "            ranks = eval_frame.iloc[i, 2:].rank(ascending=False).values\n",
        "        \n",
        "        # create single-row frame and append to rank_frame\n",
        "        row_frame = pd.DataFrame(ranks.reshape(1, ranks.shape[0]), columns=rank_names)\n",
        "        rank_frame = rank_frame.append(row_frame, ignore_index=True)\n",
        "        \n",
        "        # house keeping\n",
        "        del row_frame\n",
        "\n",
        "# merge ranks onto eval_frame\n",
        "eval_frame = pd.concat([eval_frame, rank_frame], axis=1)\n",
        "\n",
        "# house keeping\n",
        "del rank_frame\n",
        "        \n",
        "eval_frame"
      ],
      "metadata": {
        "id": "py0vini5i3QK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. Display simple ranked score list"
      ],
      "metadata": {
        "id": "zxPMrabNqZtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# average model ranks across folds and metrics\n",
        "# lower is better\n",
        "eval_frame[[name for name in eval_frame.columns if name.endswith('rank')]].mean().sort_values()"
      ],
      "metadata": {
        "id": "2f73yMzGqXI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Select best model"
      ],
      "metadata": {
        "id": "irXiatrwqpcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_glm_index =  # REQUIRES STUDENT INPUT: SELECT MODEL 0, 1, 2 or 3\n",
        "best_glm = loan_grid.get_grid()[best_glm_index]"
      ],
      "metadata": {
        "id": "eLDpb0WQqwbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Determine honest estimate of test AUC"
      ],
      "metadata": {
        "id": "9HFWrla2rEjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "htest = h2o.H2OFrame() # REQUIRES STUDENT INPUT: SELECT CORRECT PARTITION\n",
        "auc = best_glm.model_performance(htest).auc()\n",
        "print('Best GLM test AUC: %.4f' % auc)"
      ],
      "metadata": {
        "id": "RVkDR0QNrNsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. Generate a prediction for a new customer"
      ],
      "metadata": {
        "id": "TFE7ZrWptGww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict on new data -- REQUIRES STUDENT INPUT\n",
        "new_row = h2o.H2OFrame({\n",
        "  \"GRP_REP_home_ownership\": ,\n",
        "  \"GRP_addr_state\": ,\n",
        "  \"GRP_purpose\": ,\n",
        "  \"GRP_verification_status\": ,\n",
        "  \"STD_IMP_REP_annual_inc\": ,\n",
        "  \"STD_IMP_REP_delinq_2yrs\": ,\n",
        "  \"STD_IMP_REP_dti\": ,\n",
        "  \"STD_IMP_REP_emp_length\": ,\n",
        "  \"STD_IMP_REP_int_rate\": ,\n",
        "  \"STD_IMP_REP_loan_amnt\": ,\n",
        "  \"STD_IMP_REP_longest_credit_lengt\": ,\n",
        "  \"STD_IMP_REP_revol_util\": ,\n",
        "  \"STD_IMP_REP_term_length\": ,\n",
        "  \"STD_IMP_REP_total_acc\": \n",
        "}) \n",
        "\n",
        "# generate prediction -- REQUIRES STUDENT INPUT\n"
      ],
      "metadata": {
        "id": "qTIDheZ3tFTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwXbw3I_sfkW"
      },
      "source": [
        "24. Shutdown h2o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HloLeeKTPkG_"
      },
      "outputs": [],
      "source": [
        "# shutdown h2o\n",
        "h2o.cluster().shutdown()"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "collapsed_sections": [],
      "name": "Assignment 3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}